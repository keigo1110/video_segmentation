#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å‹•çš„ç‰©ä½“æ¤œå‡ºã¨ãƒã‚¹ã‚¯å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import cv2
import numpy as np
import json
import time

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from depth_estimator import DepthEstimator
from point_cloud_processor import PointCloudProcessor
from segmentation import SegmentationModel
from dynamic_object_detector import DynamicObjectDetector

def load_camera_params_from_colmap(cameras_txt):
    """
    COLMAPã®ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        cameras_txt: COLMAPã®ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        ã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (fx, fy, cx, cy)
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’èª­ã‚€
    with open(cameras_txt, 'r') as f:
        lines = f.readlines()
    
    # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
    camera_lines = [line for line in lines if not line.startswith('#')]
    
    # æœ€åˆã®ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨
    if camera_lines:
        parts = camera_lines[0].strip().split()
        # CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]
        fx = float(parts[4])
        fy = float(parts[4])  # å¤šãã®å ´åˆã€fx = fy
        cx = float(parts[5])
        cy = float(parts[6])
        
        return (fx, fy, cx, cy)
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return (1000.0, 1000.0, 960.0, 540.0)

def create_test_camera_pose():
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºã‚’ä½œæˆ
    
    Returns:
        latest_pose, past_pose: æœ€æ–°ã¨éå»ã®ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºè¡Œåˆ—
    """
    # å˜ä½è¡Œåˆ—ï¼ˆè¦–ç‚¹ã®å¤‰åŒ–ãªã—ï¼‰
    identity = np.eye(4)
    
    # éå»ã‚«ãƒ¡ãƒ©ã¯å¤§ããç§»å‹•ã¨å›è»¢ã‚’åŠ ãˆã‚‹ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šã®æœ¬ã‚’è¦‹ã‚‹è¦–ç‚¹ã®å¤‰åŒ–ã‚’å¼·èª¿ï¼‰
    past_pose = np.eye(4)
    past_pose[0, 3] = 0.6  # Xè»¸æ–¹å‘ã«60cmç§»å‹•ï¼ˆå¤‰æ›´: 0.5â†’0.6ï¼‰
    past_pose[1, 3] = 0.3  # Yè»¸æ–¹å‘ã«30cmç§»å‹•ï¼ˆå¤‰æ›´: 0.2â†’0.3ï¼‰
    
    # ã‚ˆã‚Šå¤§ããªå›è»¢ã‚’åŠ ãˆã‚‹ï¼ˆYè»¸å‘¨ã‚Šã«å›è»¢ï¼‰
    theta = np.radians(15)  # 15åº¦ã®å›è»¢ï¼ˆå¤‰æ›´: 10â†’15ï¼‰
    c, s = np.cos(theta), np.sin(theta)
    rotation_y = np.array([
        [c, 0, s, 0],
        [0, 1, 0, 0],
        [-s, 0, c, 0],
        [0, 0, 0, 1]
    ])
    
    # Xè»¸å‘¨ã‚Šã®å›è»¢ã‚‚è¿½åŠ ï¼ˆè¦‹ä¸‹ã‚ã™è§’åº¦ã®å¤‰åŒ–ï¼‰
    phi = np.radians(8)  # 8åº¦ã®å›è»¢ï¼ˆå¤‰æ›´: 5â†’8ï¼‰
    c, s = np.cos(phi), np.sin(phi)
    rotation_x = np.array([
        [1, 0, 0, 0],
        [0, c, -s, 0],
        [0, s, c, 0],
        [0, 0, 0, 1]
    ])
    
    # å›è»¢ã‚’é©ç”¨ï¼ˆæœ€åˆã«Yè»¸å›è»¢ã€æ¬¡ã«Xè»¸å›è»¢ï¼‰
    past_pose = np.dot(rotation_x, np.dot(rotation_y, past_pose))
    
    return identity, past_pose

def main():
    print("å‹•çš„ç‰©ä½“æ¤œå‡ºã¨ãƒã‚¹ã‚¯å‡¦ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹è¨­å®š
    test_data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "test_data")
    latest_image_path = os.path.join(test_data_dir, "jaquar0247.jpeg")
    past_image_path = os.path.join(test_data_dir, "jaquar0124.jpeg")
    cameras_file = os.path.join(test_data_dir, "cameras.txt")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "output")
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”»åƒã®èª­ã¿è¾¼ã¿
    latest_image = cv2.imread(latest_image_path)
    past_image = cv2.imread(past_image_path)
    
    if latest_image is None or past_image is None:
        print(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {latest_image_path} ã¾ãŸã¯ {past_image_path}")
        sys.exit(1)
    
    print(f"æœ€æ–°ç”»åƒã‚µã‚¤ã‚º: {latest_image.shape}")
    print(f"éå»ç”»åƒã‚µã‚¤ã‚º: {past_image.shape}")
    
    # ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    camera_intrinsics = load_camera_params_from_colmap(cameras_file)
    print(f"ã‚«ãƒ¡ãƒ©å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: fx={camera_intrinsics[0]}, fy={camera_intrinsics[1]}, cx={camera_intrinsics[2]}, cy={camera_intrinsics[3]}")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºã‚’ä½œæˆ
    latest_pose, past_pose = create_test_camera_pose()
    print(f"æœ€æ–°ç”»åƒã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚º:\n{latest_pose}")
    print(f"éå»ç”»åƒã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚º:\n{past_pose}")
    
    # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    print("\nãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    depth_model = DepthEstimator()
    segmentation_model = SegmentationModel()
    point_cloud_processor = PointCloudProcessor()
    dynamic_detector = DynamicObjectDetector(dynamic_threshold=0.08)  # å‹•çš„é–¾å€¤ã‚’ã•ã‚‰ã«ä¸‹ã’ã‚‹: 0.10 â†’ 0.08
    
    # å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    distance_threshold = 0.05  # å‹•çš„ç‰©ä½“ã¨åˆ¤å®šã™ã‚‹è·é›¢é–¾å€¤ã‚’ã•ã‚‰ã«ä¸‹ã’ã‚‹: 0.08 â†’ 0.05
    
    # å‡¦ç†é–‹å§‹
    print("\n=== å‹•çš„ç‰©ä½“æ¤œå‡ºå‡¦ç†ã‚’é–‹å§‹ ===")
    
    # 1. æ·±åº¦æ¨å®š
    print("1. æ·±åº¦æ¨å®šä¸­...")
    latest_depth = depth_model.estimate_depth(latest_image)
    past_depth = depth_model.estimate_depth(past_image)
    
    # æ·±åº¦ãƒãƒƒãƒ—ã®çµ±è¨ˆæƒ…å ±
    print(f"æœ€æ–°ç”»åƒæ·±åº¦ç¯„å›²: {np.min(latest_depth):.2f}mï½{np.max(latest_depth):.2f}mã€å¹³å‡: {np.mean(latest_depth):.2f}m")
    print(f"éå»ç”»åƒæ·±åº¦ç¯„å›²: {np.min(past_depth):.2f}mï½{np.max(past_depth):.2f}mã€å¹³å‡: {np.mean(past_depth):.2f}m")
    
    # æ·±åº¦ãƒãƒƒãƒ—ã‚’å¯è¦–åŒ–ã—ã¦ä¿å­˜
    latest_depth_vis = cv2.normalize(latest_depth, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    past_depth_vis = cv2.normalize(past_depth, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’é©ç”¨ã—ã¦è©³ç´°ã«å¯è¦–åŒ–
    latest_depth_color = cv2.applyColorMap(latest_depth_vis, cv2.COLORMAP_JET)
    past_depth_color = cv2.applyColorMap(past_depth_vis, cv2.COLORMAP_JET)
    
    cv2.imwrite(os.path.join(output_dir, "latest_depth.jpg"), latest_depth_vis)
    cv2.imwrite(os.path.join(output_dir, "past_depth.jpg"), past_depth_vis)
    cv2.imwrite(os.path.join(output_dir, "latest_depth_color.jpg"), latest_depth_color)
    cv2.imwrite(os.path.join(output_dir, "past_depth_color.jpg"), past_depth_color)
    
    # 2. ç‚¹ç¾¤ç”Ÿæˆ
    print("2. ç‚¹ç¾¤ç”Ÿæˆä¸­...")
    latest_points = depth_model.generate_point_cloud(latest_image, latest_depth, camera_intrinsics)
    past_points = depth_model.generate_point_cloud(past_image, past_depth, camera_intrinsics)
    
    print(f"æœ€æ–°ç”»åƒã®ç‚¹æ•°: {len(latest_points)}")
    print(f"éå»ç”»åƒã®ç‚¹æ•°: {len(past_points)}")
    
    # ç‚¹ç¾¤ã®çµ±è¨ˆæƒ…å ±
    print(f"æœ€æ–°ç”»åƒç‚¹ç¾¤ Xç¯„å›²: [{np.min(latest_points[:,0]):.2f}, {np.max(latest_points[:,0]):.2f}]")
    print(f"æœ€æ–°ç”»åƒç‚¹ç¾¤ Yç¯„å›²: [{np.min(latest_points[:,1]):.2f}, {np.max(latest_points[:,1]):.2f}]")
    print(f"æœ€æ–°ç”»åƒç‚¹ç¾¤ Zç¯„å›²: [{np.min(latest_points[:,2]):.2f}, {np.max(latest_points[:,2]):.2f}]")
    print(f"éå»ç”»åƒç‚¹ç¾¤ Xç¯„å›²: [{np.min(past_points[:,0]):.2f}, {np.max(past_points[:,0]):.2f}]")
    print(f"éå»ç”»åƒç‚¹ç¾¤ Yç¯„å›²: [{np.min(past_points[:,1]):.2f}, {np.max(past_points[:,1]):.2f}]")
    print(f"éå»ç”»åƒç‚¹ç¾¤ Zç¯„å›²: [{np.min(past_points[:,2]):.2f}, {np.max(past_points[:,2]):.2f}]")
    
    # 3. éå»ç”»åƒã®ç‚¹ç¾¤ã‚’æœ€æ–°ç”»åƒã®è¦–ç‚¹ã«å¤‰æ›
    print("3. ç‚¹ç¾¤åº§æ¨™å¤‰æ›ä¸­...")
    past_points_transformed = point_cloud_processor.transform_point_cloud(past_points, past_pose)
    
    # å¤‰æ›å¾Œã®ç‚¹ç¾¤çµ±è¨ˆæƒ…å ±
    print(f"å¤‰æ›å¾Œã®éå»ç”»åƒç‚¹ç¾¤ Xç¯„å›²: [{np.min(past_points_transformed[:,0]):.2f}, {np.max(past_points_transformed[:,0]):.2f}]")
    print(f"å¤‰æ›å¾Œã®éå»ç”»åƒç‚¹ç¾¤ Yç¯„å›²: [{np.min(past_points_transformed[:,1]):.2f}, {np.max(past_points_transformed[:,1]):.2f}]")
    print(f"å¤‰æ›å¾Œã®éå»ç”»åƒç‚¹ç¾¤ Zç¯„å›²: [{np.min(past_points_transformed[:,2]):.2f}, {np.max(past_points_transformed[:,2]):.2f}]")
    
    # å¤‰æ›ã®å¯è¦–åŒ–ï¼ˆç‚¹ç¾¤ã‚’Zæ–¹å‘ã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã§ç”»åƒã«æŠ•å½±ï¼‰
    def visualize_point_cloud(points, image_shape, camera_intrinsics, name):
        fx, fy, cx, cy = camera_intrinsics
        height, width = image_shape[:2]
        
        # Zå€¤ã«åŸºã¥ã„ã¦è‰²ä»˜ã‘
        z_min, z_max = np.min(points[:,2]), np.max(points[:,2])
        z_normalized = (points[:,2] - z_min) / (z_max - z_min)
        
        # å¯è¦–åŒ–ç”¨ã®ç”»åƒã‚’ä½œæˆ
        vis_image = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ç‚¹ã‚’ç”»åƒã«æŠ•å½±
        for i, (x, y, z) in enumerate(points[:,:3]):
            if z > 0:  # å‰æ–¹ã®ç‚¹ã®ã¿
                px = int((fx * x / z) + cx)
                py = int((fy * y / z) + cy)
                
                if 0 <= px < width and 0 <= py < height:
                    # Zå€¤ã«å¿œã˜ãŸè‰²ï¼ˆèµ¤:è¿‘ã„ã€é’:é ã„ï¼‰
                    color = [
                        int(255 * (1 - z_normalized[i])),  # B
                        0,                                # G
                        int(255 * z_normalized[i])         # R
                    ]
                    vis_image[py, px] = color
        
        # ç©´ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«è†¨å¼µã¨ä¾µé£Ÿ
        kernel = np.ones((3, 3), np.uint8)
        vis_image = cv2.dilate(vis_image, kernel, iterations=1)
        
        return vis_image
    
    # ç‚¹ç¾¤ã®å¯è¦–åŒ–
    latest_points_vis = visualize_point_cloud(latest_points, latest_image.shape, camera_intrinsics, "latest")
    past_points_vis = visualize_point_cloud(past_points, past_image.shape, camera_intrinsics, "past")
    past_transformed_vis = visualize_point_cloud(past_points_transformed, latest_image.shape, camera_intrinsics, "past_transformed")
    
    cv2.imwrite(os.path.join(output_dir, "latest_points.jpg"), latest_points_vis)
    cv2.imwrite(os.path.join(output_dir, "past_points.jpg"), past_points_vis)
    cv2.imwrite(os.path.join(output_dir, "past_transformed_points.jpg"), past_transformed_vis)
    
    # 4. ç‚¹ç¾¤æ¯”è¼ƒï¼ˆæœ€è¿‘å‚æ¢ç´¢ã§å‹•çš„ç‚¹ã‚’æ¤œå‡ºï¼‰
    print("4. ç‚¹ç¾¤æ¯”è¼ƒï¼ˆå‹•çš„ç‰©ä½“æ¤œå‡ºï¼‰ä¸­...")
    latest_index = point_cloud_processor.build_faiss_index(latest_points)
    
    dynamic_indices, distances = point_cloud_processor.find_nearest_neighbors(
        past_points_transformed, latest_index, distance_threshold=distance_threshold
    )
    
    # å‹•çš„ç‚¹ç¾¤ã®å¯è¦–åŒ–
    dynamic_points_mask = np.zeros(len(past_points_transformed), dtype=bool)
    dynamic_points_mask[dynamic_indices] = True
    
    # å‹•çš„ç‚¹ã¨é™çš„ç‚¹ã‚’åˆ†ã‘ã¦å¯è¦–åŒ–
    def visualize_dynamic_points(points, dynamic_mask, image_shape, camera_intrinsics, name):
        fx, fy, cx, cy = camera_intrinsics
        height, width = image_shape[:2]
        
        # å¯è¦–åŒ–ç”¨ã®ç”»åƒã‚’ä½œæˆ
        vis_image = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šï¼ˆYåº§æ¨™ã®ç‰¹å®šç¯„å›²ï¼‰ã®ç‚¹ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ãƒã‚¹ã‚¯
        table_mask = (points[:, 1] > -1.0) & (points[:, 1] < -0.3)
        
        # ç‚¹ã‚’ç”»åƒã«æŠ•å½±
        for i, (x, y, z) in enumerate(points[:,:3]):
            if z > 0:  # å‰æ–¹ã®ç‚¹ã®ã¿
                px = int((fx * x / z) + cx)
                py = int((fy * y / z) + cy)
                
                if 0 <= px < width and 0 <= py < height:
                    # å‹•çš„ç‚¹ã¯èµ¤ã€ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šã®ç‚¹ã¯ç·‘ã€ãã®ä»–ã®é™çš„ç‚¹ã¯é’
                    if dynamic_mask[i]:
                        color = [0, 0, 255]  # èµ¤: å‹•çš„ç‚¹
                    elif table_mask[i]:
                        color = [0, 255, 0]  # ç·‘: ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šã®ç‚¹
                    else:
                        color = [255, 0, 0]  # é’: ãã®ä»–ã®é™çš„ç‚¹
                    vis_image[py, px] = color
        
        # ç©´ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«è†¨å¼µ
        kernel = np.ones((3, 3), np.uint8)
        vis_image = cv2.dilate(vis_image, kernel, iterations=1)
        
        return vis_image
    
    # å‹•çš„ç‚¹ã®å¯è¦–åŒ–
    dynamic_points_vis = visualize_dynamic_points(past_points_transformed, dynamic_points_mask, latest_image.shape, camera_intrinsics, "dynamic_points")
    cv2.imwrite(os.path.join(output_dir, "dynamic_points.jpg"), dynamic_points_vis)
    
    # 5. éå»ç”»åƒã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
    print("5. éå»ç”»åƒã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...")
    past_segments = segmentation_model.segment_image(past_image)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’å¯è¦–åŒ–
    past_image_with_segments = past_image.copy()
    segment_colors = {}
    
    # ç‰¹å®šç‰©ä½“ï¼ˆæœ¬ãªã©ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹æƒ…å ±
    object_of_interest = {
        'center_x': 960,  # ç”»åƒã®ä¸­å¤®ä»˜è¿‘
        'center_y': 540,
        'width': 300,     # ã‚ã‚‹ç¨‹åº¦ã®å¤§ãã•ï¼ˆæœ¬ã®å¤§ãã•ï¼‰
        'height': 300
    }
    
    # æœ¬ã®å€™è£œã¨ãªã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
    book_segment_indices = []
    
    for i, seg in enumerate(past_segments):
        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å›ºæœ‰ã®è‰²ã‚’å‰²ã‚Šå½“ã¦
        if i not in segment_colors:
            segment_colors[i] = (
                np.random.randint(0, 255),
                np.random.randint(0, 255),
                np.random.randint(0, 255)
            )
        
        mask = seg['mask'].astype(np.uint8)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(past_image_with_segments, contours, -1, segment_colors[i], 2)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ä½ç½®ã¨å¤§ãã•ã‚’è¨ˆç®—
        x, y, w, h = cv2.boundingRect(contours[0])
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’æç”»
        M = cv2.moments(contours[0])
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(past_image_with_segments, str(i), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é¢ç©
            segment_area = cv2.contourArea(contours[0])
            
            # ç‰¹å®šã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡ºï¼ˆæœ¬ãªã©ã®å‹•çš„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
            # ä½ç½®ã¨å¤§ãã•ã‚’è€ƒæ…®
            is_in_center = abs(cx - object_of_interest['center_x']) < 300 and abs(cy - object_of_interest['center_y']) < 200
            is_book_size = 2000 < segment_area < 30000 and 50 < w < 400 and 50 < h < 400
            
            if is_in_center and is_book_size:
                print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}ã¯æœ¬ãªã©ã®å¯¾è±¡ç‰©ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„: é¢ç©={segment_area}, ä½ç½®=({cx},{cy}), ã‚µã‚¤ã‚º=({w}x{h})")
                book_segment_indices.append(i)
        
    # è¿½åŠ ã®è¦–è¦šåŒ–ï¼šç‰¹å®šã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ç‰¹åˆ¥ãªãƒãƒ¼ã‚­ãƒ³ã‚°
    for book_idx in book_segment_indices:
        seg = past_segments[book_idx]
        mask = seg['mask'].astype(np.uint8)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        # æœ¬ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’èµ¤ã„å¤ªç·šã§å¼·èª¿
        cv2.drawContours(past_image_with_segments, contours, -1, (0, 0, 255), 4)
        # ã€Œæœ¬ã€ã¨ã„ã†ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        M = cv2.moments(contours[0])
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(past_image_with_segments, f"{book_idx}:BOOK", (cx-30, cy-20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    
    cv2.imwrite(os.path.join(output_dir, "past_segmentation.jpg"), past_image_with_segments)
    
    # 6. å‹•çš„ç‚¹ç¾¤ã®æŠ•å½±ï¼†å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ¤œå‡º
    print("6. å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¤œå‡ºä¸­...")
    image_points, valid_mask = dynamic_detector.project_points_to_image(
        past_points_transformed, camera_intrinsics, past_image.shape
    )
    
    dynamic_segment_indices, segment_ratios = dynamic_detector.detect_dynamic_segments(
        dynamic_indices, image_points, valid_mask, past_segments
    )
    
    # å‹•çš„ç‚¹ã®é›†åˆã‚’å–å¾—ï¼ˆHashSetã§é«˜é€Ÿãªæ¤œç´¢ç”¨ï¼‰
    dynamic_points_set = set(dynamic_indices)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®è©³ç´°åˆ†æ
    print("\n--- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°åˆ†æ ---")
    segment_analysis = []
    book_segment_candidates = []
    
    for i, seg in enumerate(past_segments):
        mask = seg['mask'].astype(np.uint8)
        segment_area = np.sum(mask)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ç‚¹ã®ä½ç½®ã‚’åˆ†æï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å¯¾å¿œã™ã‚‹3Dç‚¹ã‚’ç‰¹å®šï¼‰
        segment_points = []
        for j in range(len(image_points)):
            if valid_mask[j]:
                x, y = image_points[j]
                if 0 <= y < mask.shape[0] and 0 <= x < mask.shape[1] and mask[y, x]:
                    segment_points.append(j)
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        if segment_points:
            # æ·±åº¦æƒ…å ±
            depths = past_points_transformed[segment_points, 2]
            mean_depth = np.mean(depths)
            
            # 3Dåº§æ¨™æƒ…å ±ï¼ˆç‰¹ã«Yåº§æ¨™ = é«˜ã•ï¼‰
            y_coords = past_points_transformed[segment_points, 1]
            mean_y = np.mean(y_coords) if len(y_coords) > 0 else 0
            
            # å‹•çš„ãƒ”ã‚¯ã‚»ãƒ«ã®å‰²åˆ
            dynamic_pixels = [p for p in segment_points if p in dynamic_points_set]
            dynamic_count = len(dynamic_pixels)
            dynamic_ratio = dynamic_count / len(segment_points) if segment_points else 0
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’ä¿å­˜
            segment_info = {
                'index': i,
                'area': segment_area,
                'mean_y': mean_y,
                'mean_depth': mean_depth,
                'dynamic_ratio': dynamic_ratio,
                'dynamic_count': dynamic_count,
                'total_points': len(segment_points)
            }
            segment_analysis.append(segment_info)
            
            # å‡ºåŠ›æƒ…å ±
            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}: é¢ç©={segment_area}px, å¹³å‡é«˜ã•={mean_y:.2f}m, å¹³å‡æ·±åº¦={mean_depth:.2f}m, å‹•çš„ç‡={dynamic_ratio:.3f} ({dynamic_count}/{len(segment_points)})")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šã®ç‰©ä½“å€™è£œã‚’æ¤œå‡ºï¼ˆé«˜ã•ã¨é¢ç©ã§åˆ¤å®šï¼‰
            table_top_y = -0.7  # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒˆãƒƒãƒ—ä»˜è¿‘ã®Yåº§æ¨™ï¼ˆè² ã®å€¤ãªã®ã§æ³¨æ„ï¼‰
            is_on_table = mean_y > (table_top_y - 0.3) and mean_y < (table_top_y + 0.3)  # ãƒ†ãƒ¼ãƒ–ãƒ«é¢ã®å‰å¾Œ30cm
            is_book_size = segment_area > 2000 and segment_area < 30000  # æœ¬ã‚‰ã—ã„ã‚µã‚¤ã‚º
            
            if is_on_table and is_book_size:
                book_segment_candidates.append(segment_info)
                print(f"  ğŸ‘‰ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}ã¯æœºã®ä¸Šã®æœ¬ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ï¼")
    
    print("\n--- æœ¬ã®å€™è£œã¨ãªã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ---")
    for book in sorted(book_segment_candidates, key=lambda x: x['area'], reverse=True):
        idx = book['index']
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{idx}: é¢ç©={book['area']}px, é«˜ã•={book['mean_y']:.2f}m, å‹•çš„ç‡={book['dynamic_ratio']:.3f}")
        
        # æœ¬å€™è£œã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å¼·åˆ¶çš„ã«å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
        if idx not in dynamic_segment_indices:
            print(f"  ğŸ‘‰ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{idx}ã‚’å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦å¼·åˆ¶è¿½åŠ ")
            dynamic_segment_indices.append(idx)
    
    # ç‰¹å®šã—ãŸæœ¬ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚‚å¼·åˆ¶çš„ã«å‹•çš„ã¨ã—ã¦è¿½åŠ 
    for book_idx in book_segment_indices:
        if book_idx not in dynamic_segment_indices:
            print(f"  ğŸ‘‰ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{book_idx}ï¼ˆæœ¬ï¼‰ã‚’å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦å¼·åˆ¶è¿½åŠ ")
            dynamic_segment_indices.append(book_idx)
    
    print(f"\nå‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¤œå‡ºçµæœ: {len(dynamic_segment_indices)}/{len(past_segments)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒå‹•çš„ã¨åˆ¤å®š")
    print(f"å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {sorted(dynamic_segment_indices)}")
    
    # å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å¯è¦–åŒ–
    dynamic_segments_vis = past_image.copy()
    
    for i, seg in enumerate(past_segments):
        mask = seg['mask'].astype(np.uint8)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # å‹•çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯èµ¤ã€é™çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ç·‘ã§è¡¨ç¤º
        color = (0, 0, 255) if i in dynamic_segment_indices else (0, 255, 0)
        cv2.drawContours(dynamic_segments_vis, contours, -1, color, 2)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’æç”»
        M = cv2.moments(contours[0])
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(dynamic_segments_vis, str(i), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        segment_area = np.sum(mask)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã¨æœ¬ã«é–¢é€£ã™ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ç‰¹å¾´ã‚’å‡ºåŠ›
        if segment_area > 1000 and segment_area < 50000:  # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„æœ¬ã‚‰ã—ãã‚µã‚¤ã‚ºåˆ¶é™
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ç‚¹ã®ä½ç½®ã‚’åˆ†æ
            segment_points = []
            for j in range(len(image_points)):
                if valid_mask[j]:
                    x, y = image_points[j]
                    if 0 <= y < mask.shape[0] and 0 <= x < mask.shape[1] and mask[y, x]:
                        segment_points.append(j)
            
            if segment_points:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ç‚¹ã®å¹³å‡Yåº§æ¨™ï¼ˆæœºã®é«˜ã•ã«é–¢é€£ï¼‰ã‚’è¨ˆç®—
                y_coords = past_points_transformed[segment_points, 1]
                mean_y = np.mean(y_coords) if len(y_coords) > 0 else 0
                
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®å‹•çš„ãƒ”ã‚¯ã‚»ãƒ«ã®å‰²åˆ
                dynamic_count = sum(1 for p in segment_points if p in dynamic_segment_indices)
                dynamic_ratio = dynamic_count / len(segment_points) if segment_points else 0
                
                print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}ã®è©³ç´°: é¢ç©={segment_area}px, å¹³å‡Yåº§æ¨™={mean_y:.2f}m, å‹•çš„ç‡={dynamic_ratio:.2f}")
                
                # æœºã®ä¸Šã«ä½ç½®ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç‰¹å®š
                is_on_table = mean_y > -0.9 and mean_y < -0.3  # æœºã®é«˜ã•ä»˜è¿‘
                if is_on_table:
                    print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{i}ã¯æœºã®ä¸Šã«ä½ç½®ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„")
                    
                    # æœºã®ä¸Šã§å‹•çš„ã§ã¯ãªã„å ´åˆã¯ç‰¹ã«æ³¨ç›®
                    if i not in dynamic_segment_indices and dynamic_ratio > 0.05:
                        print(f"  âš ï¸ ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯æœ¬ãªã©ã®å‹•çš„ç‰©ä½“ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“!")
                        print(f"  å‹•çš„ãƒ”ã‚¯ã‚»ãƒ«ã‚ã‚Š: {dynamic_count}/{len(segment_points)}={dynamic_ratio:.2f}")

    cv2.imwrite(os.path.join(output_dir, "dynamic_segments.jpg"), dynamic_segments_vis)
    
    # 7. å‹•çš„ãƒã‚¹ã‚¯ã®ç”Ÿæˆ
    print("7. å‹•çš„ãƒã‚¹ã‚¯ç”Ÿæˆä¸­...")
    dynamic_mask = dynamic_detector.create_dynamic_mask(
        dynamic_segment_indices, past_segments, past_image.shape
    )
    
    # 8. ãƒã‚¹ã‚¯é©ç”¨
    print("8. ãƒã‚¹ã‚¯é©ç”¨ä¸­...")
    masked_past_image = dynamic_detector.apply_mask_to_image(past_image, dynamic_mask)
    
    # 9. çµæœã®å¯è¦–åŒ–
    print("9. çµæœã®å¯è¦–åŒ–...")
    
    # ãƒã‚¹ã‚¯ç”»åƒã‚’å¯è¦–åŒ–ï¼ˆç™½é»’ã®2å€¤ç”»åƒã‚’ç–‘ä¼¼ã‚«ãƒ©ãƒ¼åŒ–ï¼‰
    color_mask = cv2.applyColorMap((dynamic_mask * 255).astype(np.uint8), cv2.COLORMAP_JET)
    
    # é€æ˜åº¦ä»˜ãã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’ä½œæˆ
    alpha = 0.5
    overlay = cv2.addWeighted(past_image, 1-alpha, color_mask, alpha, 0)
    
    # æ¯”è¼ƒè¡¨ç¤ºç”¨ã«ç”»åƒã‚’ä¸¦ã¹ã‚‹
    h, w = latest_image.shape[:2]
    h_new, w_new = h, w * 4  # 4ã¤ã®ç”»åƒã‚’æ¨ªã«ä¸¦ã¹ã‚‹
    
    comparison = np.zeros((h_new, w_new, 3), dtype=np.uint8)
    comparison[:, :w] = latest_image
    comparison[:, w:w*2] = past_image
    comparison[:, w*2:w*3] = masked_past_image
    comparison[:, w*3:] = overlay
    
    # ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(comparison, "Latest Image", (10, 30), font, 1, (0, 255, 0), 2)
    cv2.putText(comparison, "Past Image", (w+10, 30), font, 1, (0, 255, 0), 2)
    cv2.putText(comparison, "Masked Image", (w*2+10, 30), font, 1, (0, 255, 0), 2)
    cv2.putText(comparison, "Dynamic Mask", (w*3+10, 30), font, 1, (0, 255, 0), 2)
    
    # çµæœã‚’ä¿å­˜
    timestamp = int(time.time())
    cv2.imwrite(os.path.join(output_dir, f"comparison_{timestamp}.jpg"), comparison)
    cv2.imwrite(os.path.join(output_dir, "latest.jpg"), latest_image)
    cv2.imwrite(os.path.join(output_dir, "past.jpg"), past_image)
    cv2.imwrite(os.path.join(output_dir, "masked.jpg"), masked_past_image)
    cv2.imwrite(os.path.join(output_dir, "mask.jpg"), dynamic_mask * 255)
    
    print(f"\nå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    
    # çµæœã‚’è¡¨ç¤º
    try:
        cv2.imshow("Results", comparison)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    except:
        print("GUIã§ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚çµæœã¯ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main() 